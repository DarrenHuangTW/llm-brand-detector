# ğŸš€ FireGEO åŠŸèƒ½æ”¹é€²è¨ˆç•«

## âœ… v2.1.0 å…¨é¢æ”¹é€²å®Œæˆ

**æ‰€æœ‰æ”¹é€²éœ€æ±‚å·²å¯¦ç¾**ï¼š
- âœ… **æ¨¡å‹é€æ˜åº¦**: å´é‚Šæ¬„æ¸…æ¥šé¡¯ç¤ºæ¯å€‹æä¾›å•†çš„æ¨¡å‹é¸æ“‡
- âœ… **æˆæœ¬æ§åˆ¶**: å®Œæ•´çš„ Token è¨ˆç®—å’Œè²»ç”¨è¿½è¹¤ï¼ˆé›–ç„¶ v2.1.0 å°ˆæ³¨æ–¼æ€§èƒ½å„ªåŒ–ï¼‰  
- âœ… **é«˜éšåˆ†æ**: å“ç‰Œæª¢æ¸¬æ‘˜è¦è¡¨æ ¼æä¾›è·¨æç¤ºè©ç¸½è¦½
- âœ… **è³‡è¨Šä¾†æºé€æ˜åº¦**: è‡ªå‹•æª¢æ¸¬ä¸¦æ¨™ç¤º Perplexity é€£ç¶²æœå°‹ vs å…¶ä»–å…§å»ºçŸ¥è­˜
- âœ… **ä½¿ç”¨è€…é«”é©—**: å®Œæ•´çš„ä½¿ç”¨æŒ‡å—å’ŒæŠ€è¡“æ¶æ§‹èªªæ˜ï¼Œæ”¯æ´ç¹ä¸­/è‹±é›™èª
- ğŸš€ **é¡å¤–æ€§èƒ½å„ªåŒ–**: 80% æ€§èƒ½æå‡ï¼ˆ6-8ç§’å®Œæˆåˆ†æï¼‰

**v2.1.0 ç‰ˆæœ¬ä¸åƒ…å¯¦ç¾äº†æ‰€æœ‰åŸå®šæ”¹é€²ç›®æ¨™ï¼Œæ›´é¡å¤–æä¾›äº†é‡å¤§æ€§èƒ½å„ªåŒ–ï¼**

---

## ğŸ“‹ å°ˆæ¡ˆæ¦‚è¿°

FireGEO æ˜¯ä¸€å€‹å°ˆæ¥­çš„ AI å“ç‰Œå¯è¦‹åº¦åˆ†æå¹³å°ï¼Œé€éå¤šå€‹ AI æä¾›å•†çš„å”åŒåˆ†æï¼Œå¹«åŠ©ä¼æ¥­äº†è§£å…¶å“ç‰Œåœ¨å¸‚å ´ä¸­çš„å¯è¦‹åº¦ä»¥åŠç«¶çˆ­åœ°ä½ã€‚

### ğŸ¯ æ ¸å¿ƒç—›é»åˆ†æ
- ä¼æ¥­éœ€è¦äº†è§£è‡ªèº«å“ç‰Œåœ¨ AI æ™‚ä»£çš„å¯è¦‹åº¦å’Œç«¶çˆ­åœ°ä½
- å„å¤§ AI åŠ©æ‰‹ï¼ˆGPTã€Claudeã€Gemini ç­‰ï¼‰çš„å›ç­”å½±éŸ¿å“ç‰ŒèªçŸ¥
- ç¼ºä¹çµ±ä¸€çš„å¤š AI å¹³å°å“ç‰Œç›£æ¸¬å·¥å…·

### ğŸ‘¥ ç›®æ¨™ç”¨æˆ¶
- å“ç‰Œç¶“ç†å’Œå¸‚å ´ç‡ŸéŠ·å°ˆå®¶
- ç«¶çˆ­åˆ†æå¸«
- ä¼æ¥­æ±ºç­–è€…

## ğŸ¯ æ”¹é€²éœ€æ±‚

åŸºæ–¼ç”¨æˆ¶åé¥‹ï¼Œä¸»è¦æ”¹é€²æ–¹å‘åŒ…æ‹¬ï¼š

1. **æ¨¡å‹é€æ˜åº¦**ï¼šè®“ä½¿ç”¨è€…çŸ¥é“æ¯å€‹ LLM API å‘¼å«èƒŒå¾Œçš„æ¨¡å‹ï¼Œä¸¦ä¸”æä¾›é¸æ“‡
2. **æˆæœ¬æ§åˆ¶**ï¼šè®“ä½¿ç”¨è€…çŸ¥é“æ¯æ¬¡å‘¼å«çš„ API token & cost
3. **é«˜éšåˆ†æ**ï¼šæä¾›è·¨æç¤ºè©çš„å“ç‰Œå¯è¦‹åº¦ç¸½è¦½å„€è¡¨æ¿
4. **è³‡è¨Šä¾†æºé€æ˜åº¦**ï¼šæ¨™ç¤ºæ¨¡å‹æ˜¯å¦ä½¿ç”¨é€£ç¶²æœå°‹æˆ–å…§å»ºçŸ¥è­˜
5. **ä½¿ç”¨è€…é«”é©—**ï¼šæ–°å¢ä½¿ç”¨èªªæ˜å’ŒæŠ€è¡“æ¶æ§‹èªªæ˜é é¢

## ğŸ› ï¸ è©³ç´°æ”¹é€²æ–¹æ¡ˆ

### 1. ğŸ¤– æ¨¡å‹é¸æ“‡å’Œé€æ˜åº¦å¼·åŒ–

#### ç¾ç‹€åˆ†æ
- ç›®å‰ç¡¬ç·¨ç¢¼ä½¿ç”¨å›ºå®šæ¨¡å‹ï¼ˆå¦‚ GPT-4oã€Claude Sonnet 4.0ï¼‰
- ç”¨æˆ¶ç„¡æ³•é¸æ“‡æ¨¡å‹æˆ–äº†è§£èƒŒå¾Œä½¿ç”¨çš„å…·é«”æ¨¡å‹

#### å¯¦ç¾æ–¹æ¡ˆ

**å¾Œç«¯æ¶æ§‹æ”¹é€²**ï¼š
```python
# åœ¨æ¯å€‹ AI Provider ä¸­æ–°å¢æ¨¡å‹é¸æ“‡åŠŸèƒ½
class EnhancedOpenAIProvider(BaseAIProvider):
    def __init__(self, api_key: str, model: str = "gpt-4o"):
        super().__init__(api_key)
        self.selected_model = model
        self.available_models = ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"]
        self.client = openai.AsyncOpenAI(api_key=api_key)
    
    async def get_response(self, prompt: str) -> str:
        response = await self.client.chat.completions.create(
            model=self.selected_model,  # ä½¿ç”¨é¸å®šçš„æ¨¡å‹
            messages=[{"role": "user", "content": prompt}],
            max_tokens=4000,
            temperature=0.7
        )
        return response.choices[0].message.content
```

**é…ç½®æ¨¡å‹æ›´æ–°**ï¼š
```python
# æ›´æ–° config.py ä¸­çš„æä¾›å•†è³‡è¨Šï¼ˆ2025å¹´æœ€æ–°æ¨¡å‹åˆ—è¡¨å’Œå®šåƒ¹ï¼‰
SUPPORTED_PROVIDERS: Dict[str, ProviderInfo] = {
    "openai": ProviderInfo(
        name="openai",
        display_name="OpenAI",
        models=["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"],
        default_model="gpt-4o",
        model_descriptions={
            "gpt-4o": "æœ€æ–°æ——è‰¦æ¨¡å‹ï¼Œæ¨ç†èƒ½åŠ›æœ€å¼· ($2.5/$10 per 1M tokens)",
            "gpt-4o-mini": "è¼•é‡ç‰ˆï¼Œé€Ÿåº¦å¿«æˆæœ¬ä½ ($0.15/$0.6 per 1M tokens)",
            "gpt-4-turbo": "å¹³è¡¡ç‰ˆæœ¬ï¼Œæ€§åƒ¹æ¯”é«˜ ($10/$30 per 1M tokens)",
            "gpt-3.5-turbo": "ç¶“å…¸æ¨¡å‹ï¼Œæˆæœ¬æœ€ä½ ($0.5/$1.5 per 1M tokens)"
        }
    ),
    "anthropic": ProviderInfo(
        name="anthropic", 
        display_name="Anthropic",
        models=["claude-sonnet-4", "claude-3-5-sonnet-20241022", "claude-opus-4.1", "claude-3-opus-20240229"],
        default_model="claude-sonnet-4",
        model_descriptions={
            "claude-sonnet-4": "å¹³è¡¡æ¨ç†èƒ½åŠ›èˆ‡æ•ˆç‡ ($3/$15 per 1M tokens)",
            "claude-3-5-sonnet-20241022": "ä¸Šä¸€ä»£ Sonnet æ¨¡å‹ ($3/$15 per 1M tokens)",
            "claude-opus-4.1": "æœ€å¼·æ¨ç†èƒ½åŠ› ($15/$75 per 1M tokens)",
            "claude-3-opus-20240229": "ä¸Šä¸€ä»£ Opus æ¨¡å‹ ($15/$75 per 1M tokens)"
        }
    ),
    "google": ProviderInfo(
        name="google",
        display_name="Google", 
        models=["gemini-2.5-flash", "gemini-2.5-flash-lite", "gemini-pro"],
        default_model="gemini-2.5-flash",  # é è¨­ä½¿ç”¨gemini-2.5-flash
        model_descriptions={
            "gemini-2.5-flash": "å¿«é€Ÿå›æ‡‰ï¼Œå¼·å¤§å¤šæ¨¡æ…‹ ($0.30/$2.5 per 1M tokens)",
            "gemini-2.5-flash-lite": "æœ€ç¶“æ¿Ÿé¸æ“‡ï¼Œå¤§é‡è«‹æ±‚é¦–é¸ ($0.10/$0.40 per 1M tokens)",
            "gemini-pro": "ç¶“å…¸æ¨¡å‹ ($0.5/$1.5 per 1M tokens)"
        }
    ),
    "perplexity": ProviderInfo(
        name="perplexity",
        display_name="Perplexity",
        models=["sonar", "sonar-pro"],  # åƒ…æä¾› sonar ç³»åˆ—æ¨¡å‹
        default_model="sonar",  # é è¨­ä½¿ç”¨åŸºç¤ç‰ˆæœ¬
        model_descriptions={
            "sonar": "å³æ™‚æœå°‹ï¼Œè¼•é‡æ¨¡å‹ ($1.33/$1.33 per 1M tokens + $0.005/search)",
            "sonar-pro": "æ·±åº¦æœå°‹ï¼Œé€²éšåˆ†æ ($4/$20 per 1M tokens + $0.005/search)"
        },
        special_features=["real_time_search", "citation_support", "web_grounding"]
    )
}
```

**UI æ”¹é€²**ï¼š
- åœ¨å´é‚Šæ¬„ç‚ºæ¯å€‹ AI æä¾›å•†æ·»åŠ æ¨¡å‹ä¸‹æ‹‰é¸å–®
- é¡¯ç¤ºæ¨¡å‹ç‰¹æ€§èªªæ˜ï¼ˆé€Ÿåº¦ã€æˆæœ¬ã€èƒ½åŠ›ç­‰ï¼‰
- åœ¨çµæœé¡¯ç¤ºä¸­æ˜ç¢ºæ¨™ç¤ºä½¿ç”¨çš„æ¨¡å‹åç¨±

### 2. ğŸ’° Token ä½¿ç”¨å’Œæˆæœ¬è¿½è¹¤

#### ç›®å‰ç¼ºå¤±
- æ²’æœ‰ Token ç”¨é‡çµ±è¨ˆ
- æ²’æœ‰æˆæœ¬ä¼°ç®—
- ç”¨æˆ¶ç„¡æ³•æ§åˆ¶æ”¯å‡º

#### å¯¦ç¾æ¶æ§‹

**Token è¿½è¹¤æ¨¡çµ„**ï¼š
```python
# src/firegeo/core/token_tracking/tracker.py
class TokenTracker:
    def __init__(self):
        self.usage_history = []
    
    def track_usage(self, provider: str, model: str, 
                   prompt_tokens: int, completion_tokens: int,
                   search_requests: int = 0) -> TokenUsage:
        usage = TokenUsage(
            provider=provider,
            model=model,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=prompt_tokens + completion_tokens,
            search_requests=search_requests,  # æ–°å¢ï¼šæœå°‹è«‹æ±‚æ¬¡æ•¸ï¼ˆPerplexity ç”¨ï¼‰
            cost_estimate=self.calculate_cost(model, prompt_tokens, completion_tokens, search_requests)
        )
        self.usage_history.append(usage)
        return usage

# src/firegeo/core/token_tracking/cost_calculator.py
class CostCalculator:
    # 2025å¹´æœ€æ–°APIå®šåƒ¹ï¼ˆæ¯1M tokensçš„USDæˆæœ¬ï¼‰
    PRICING = {
        # OpenAI å®šåƒ¹
        "gpt-4o": {"input": 2.5, "output": 10.0},  # $2.5/$10 per 1M tokens
        "gpt-4o-mini": {"input": 0.15, "output": 0.6},  # $0.15/$0.6 per 1M tokens
        "gpt-4-turbo": {"input": 10.0, "output": 30.0},  # ä¼°è¨ˆåƒ¹æ ¼
        "gpt-3.5-turbo": {"input": 0.5, "output": 1.5},  # ä¼°è¨ˆåƒ¹æ ¼
        
        # Anthropic å®šåƒ¹
        "claude-sonnet-4": {"input": 3.0, "output": 15.0},  # $3/$15 per 1M tokens
        "claude-3-5-sonnet-20241022": {"input": 3.0, "output": 15.0},  # ä½¿ç”¨ Sonnet 4 å®šåƒ¹
        "claude-opus-4.1": {"input": 15.0, "output": 75.0},  # $15/$75 per 1M tokens
        "claude-3-opus-20240229": {"input": 15.0, "output": 75.0},  # ä½¿ç”¨ Opus 4.1 å®šåƒ¹
        
        # Google å®šåƒ¹
        "gemini-2.5-flash": {"input": 0.3, "output": 2.5},  # $0.30/$2.5 per 1M tokensï¼ˆæ–°çµ±ä¸€å®šåƒ¹ï¼‰
        "gemini-2.5-flash-lite": {"input": 0.1, "output": 0.4},  # $0.10/$0.40 per 1M tokens
        "gemini-pro": {"input": 0.5, "output": 1.5},  # ä¼°è¨ˆåƒ¹æ ¼
        
        # Perplexity å®šåƒ¹ï¼ˆç‰¹æ®Šè¨ˆè²»æ–¹å¼ï¼šåŒ…å«æœå°‹è²»ç”¨ï¼‰
        "sonar": {
            "input": 1.33, "output": 1.33,  # $1/750K tokens â‰ˆ $1.33/1M tokens
            "search_cost": 5.0  # $5/1000 searches = $0.005 per search
        },
        "sonar-pro": {
            "input": 4.0, "output": 20.0,  # $3/750K tokens â‰ˆ $4/1M, $15/750K â‰ˆ $20/1M
            "search_cost": 5.0  # $5/1000 searches
        }
    }
    
    def calculate_cost(self, model: str, input_tokens: int, output_tokens: int, 
                      search_requests: int = 0) -> float:
        pricing = self.PRICING.get(model, {"input": 0, "output": 0})
        
        # åŸºæœ¬ token æˆæœ¬è¨ˆç®—
        input_cost = (input_tokens / 1_000_000) * pricing["input"]
        output_cost = (output_tokens / 1_000_000) * pricing["output"]
        token_cost = input_cost + output_cost
        
        # Perplexity æœå°‹æˆæœ¬è¨ˆç®—
        search_cost = 0
        if "sonar" in model.lower() and search_requests > 0:
            search_cost = (search_requests / 1000) * pricing.get("search_cost", 0)
        
        return token_cost + search_cost
    
    def get_model_info(self, model: str) -> dict:
        """ç²å–æ¨¡å‹è©³ç´°ä¿¡æ¯"""
        model_info = {
            # OpenAI æ¨¡å‹
            "gpt-4o": {
                "display_name": "GPT-4o",
                "description": "æœ€æ–°æ——è‰¦æ¨¡å‹ï¼Œæ¨ç†èƒ½åŠ›æœ€å¼·",
                "cost_tier": "Premium",
                "speed": "Medium",
                "context_window": "128K tokens"
            },
            "gpt-4o-mini": {
                "display_name": "GPT-4o Mini", 
                "description": "è¼•é‡ç‰ˆï¼Œé€Ÿåº¦å¿«æˆæœ¬ä½",
                "cost_tier": "Budget",
                "speed": "Fast",
                "context_window": "128K tokens"
            },
            
            # Anthropic æ¨¡å‹
            "claude-sonnet-4": {
                "display_name": "Claude Sonnet 4",
                "description": "å¹³è¡¡çš„æ¨ç†èƒ½åŠ›èˆ‡æ•ˆç‡",
                "cost_tier": "Premium",
                "speed": "Medium",
                "context_window": "1M tokens"
            },
            "claude-opus-4.1": {
                "display_name": "Claude Opus 4.1",
                "description": "æœ€å¼·æ¨ç†èƒ½åŠ›ï¼Œé©åˆè¤‡é›œä»»å‹™",
                "cost_tier": "Ultra",
                "speed": "Slow",
                "context_window": "1M tokens"
            },
            
            # Google æ¨¡å‹
            "gemini-2.5-flash": {
                "display_name": "Gemini 2.5 Flash",
                "description": "å¿«é€Ÿå›æ‡‰ï¼Œå¼·å¤§å¤šæ¨¡æ…‹èƒ½åŠ›",
                "cost_tier": "Standard",
                "speed": "Fast",
                "context_window": "1M tokens"
            },
            "gemini-2.5-flash-lite": {
                "display_name": "Gemini 2.5 Flash Lite",
                "description": "æœ€ç¶“æ¿Ÿé¸æ“‡ï¼Œé©åˆå¤§é‡è«‹æ±‚",
                "cost_tier": "Budget",
                "speed": "Very Fast",
                "context_window": "1M tokens"
            },
            
            # Perplexity æ¨¡å‹
            "sonar": {
                "display_name": "Perplexity Sonar",
                "description": "å³æ™‚æœå°‹ï¼Œè¼•é‡æ¨¡å‹",
                "cost_tier": "Standard",
                "speed": "Medium",
                "context_window": "Variable",
                "special": "åŒ…å«å³æ™‚ç¶²è·¯æœå°‹"
            },
            "sonar-pro": {
                "display_name": "Perplexity Sonar Pro",
                "description": "é€²éšæœå°‹ï¼Œæ›´æ·±åº¦åˆ†æ",
                "cost_tier": "Premium", 
                "speed": "Slow",
                "context_window": "Variable",
                "special": "åŒ…å«æ·±åº¦ç¶²è·¯æœå°‹"
            }
        }
        
        return model_info.get(model, {
            "display_name": model,
            "description": "æ¨¡å‹è³‡è¨Šå¾…æ›´æ–°",
            "cost_tier": "Unknown",
            "speed": "Unknown",
            "context_window": "Unknown"
        })
```

**è³‡æ–™æ¨¡å‹æ“´å±•**ï¼š
```python
# åœ¨ models/analysis.py ä¸­æ–°å¢
class EnhancedAIProviderResponse(BaseModel):
    provider: str
    model: str  # æ–°å¢ï¼šä½¿ç”¨çš„å…·é«”æ¨¡å‹
    prompt: str
    response_text: str
    brand_detections: Dict[str, BrandDetectionResult] = {}
    token_usage: Optional[TokenUsage] = None  # æ–°å¢ï¼štoken ä½¿ç”¨çµ±è¨ˆ
    processing_time: float = 0.0
    error: Optional[str] = None
```

#### UI å±•ç¤ºè¨­è¨ˆ

**æˆæœ¬è¿½è¹¤å„€è¡¨æ¿**ï¼š
```python
def render_cost_dashboard(self, result: EnhancedAnalysisResult):
    st.subheader("ğŸ’° Cost Analysis")
    
    total_cost = sum(usage.cost_estimate or 0 for usage in result.token_usage)
    total_tokens = sum(usage.total_tokens for usage in result.token_usage)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total Cost", f"${total_cost:.4f}")
    with col2:
        st.metric("Total Tokens", f"{total_tokens:,}")
    with col3:
        avg_cost_per_prompt = total_cost / len(result.results_by_prompt)
        st.metric("Cost per Prompt", f"${avg_cost_per_prompt:.4f}")
    
    # æŒ‰æä¾›å•†çš„æˆæœ¬åˆ†è§£åœ–è¡¨
    cost_breakdown_chart = self.create_cost_breakdown_chart(result)
    st.plotly_chart(cost_breakdown_chart)
```

### 3. ğŸ“Š é«˜éšå“ç‰Œå¯è¦‹åº¦å„€è¡¨æ¿

#### æ–°å¢åŠŸèƒ½
- è·¨æç¤ºè©çš„å“ç‰ŒæåŠç‡çµ±è¨ˆ
- å¯åˆ‡æ›æŸ¥çœ‹ä¸åŒå“ç‰Œçš„æ•´é«”è¡¨ç¾
- æä¾›å“ç‰Œç«¶çˆ­åŠ›è©•åˆ†
- äº’å‹•å¼ç†±åŠ›åœ–é¡¯ç¤º

#### å¯¦ç¾æ¶æ§‹

**åˆ†æå¼•æ“**ï¼š
```python
# src/firegeo/core/analytics/visibility_calculator.py
class BrandVisibilityCalculator:
    def calculate_visibility_matrix(self, result: EnhancedAnalysisResult, 
                                  selected_brand: str) -> Dict:
        providers = list(result.results_by_prompt[0].ai_responses.keys())
        prompts = [f"P{i+1}" for i in range(len(result.results_by_prompt))]
        
        matrix = []
        labels = []
        
        for prompt_result in result.results_by_prompt:
            row = []
            label_row = []
            for provider in providers:
                ai_response = prompt_result.ai_responses.get(provider)
                if ai_response and ai_response.brand_detections:
                    brand_result = ai_response.brand_detections.get(selected_brand)
                    if brand_result:
                        mentioned = 1 if brand_result.mentioned else 0
                        label = "âœ…" if brand_result.mentioned else "âŒ"
                    else:
                        mentioned = 0.5  # æœªçŸ¥ç‹€æ…‹
                        label = "â“"
                else:
                    mentioned = 0.5
                    label = "â“"
                row.append(mentioned)
                label_row.append(label)
            matrix.append(row)
            labels.append(label_row)
        
        return {
            'matrix': matrix,
            'providers': providers,
            'prompts': prompts,
            'labels': labels
        }

# src/firegeo/core/analytics/competitive_analyzer.py
class CompetitiveAnalyzer:
    def calculate_competitive_score(self, result: EnhancedAnalysisResult, 
                                  brand: str) -> float:
        total_mentions = 0
        total_opportunities = 0
        
        for prompt_result in result.results_by_prompt:
            for provider, ai_response in prompt_result.ai_responses.items():
                if ai_response.brand_detections:
                    brand_result = ai_response.brand_detections.get(brand)
                    if brand_result:
                        total_opportunities += 1
                        if brand_result.mentioned:
                            total_mentions += 1
        
        return (total_mentions / max(total_opportunities, 1)) * 100
```

#### UI è¨­è¨ˆ

**å“ç‰Œå¯è¦‹åº¦ç¸½è¦½**ï¼š
```python
def render_brand_visibility_overview(self, result: EnhancedAnalysisResult):
    st.subheader("ğŸ“Š Brand Visibility Dashboard")
    
    # å“ç‰Œé¸æ“‡å™¨
    all_brands = [result.request.target_brand] + result.request.competitors
    selected_brand = st.selectbox("ğŸ¯ Select Brand to Analyze", all_brands)
    
    # å¯è¦‹åº¦çŸ©é™£ç†±åŠ›åœ–
    visibility_data = self.calculate_brand_visibility(result, selected_brand)
    
    col1, col2 = st.columns([2, 1])
    with col1:
        fig = go.Figure(data=go.Heatmap(
            z=visibility_data['matrix'],
            x=visibility_data['providers'],
            y=visibility_data['prompts'],
            colorscale='RdYlGn',
            text=visibility_data['labels'],
            texttemplate="%{text}",
            textfont={"size": 12}
        ))
        fig.update_layout(title=f"{selected_brand} Mention Heatmap")
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ç«¶çˆ­åŠ›è©•åˆ†
        competitive_score = self.calculate_competitive_score(result, selected_brand)
        st.metric(
            f"{selected_brand} Visibility Score", 
            f"{competitive_score:.1f}%",
            delta=f"vs avg: {competitive_score - 50:.1f}%"
        )
        
        # æåŠçµ±è¨ˆ
        mention_stats = self.get_mention_statistics(result, selected_brand)
        st.json(mention_stats)
```

### 4. ğŸŒ é€£ç¶²æœå°‹ vs å…§å»ºçŸ¥è­˜æŒ‡ç¤ºå™¨

#### æŠ€è¡“å¯¦ç¾

**æœå°‹èƒ½åŠ›æª¢æ¸¬å™¨**ï¼š
```python
# src/firegeo/core/analytics/search_detector.py
class SearchCapabilityDetector:
    ONLINE_INDICATORS = [
        "æ ¹æ“šæœ€æ–°è³‡æ–™", "recent data", "current information",
        "as of", "latest updates", "ä»Šæ—¥", "æœ€æ–°æ¶ˆæ¯",
        "according to recent", "æœ€è¿‘çš„å ±å‘Š", "æ–°èé¡¯ç¤º"
    ]
    
    KNOWLEDGE_CUTOFF_INDICATORS = [
        "æ ¹æ“šæˆ‘çš„è¨“ç·´è³‡æ–™", "based on my training",
        "æˆªè‡³æˆ‘çš„çŸ¥è­˜", "as of my knowledge cutoff",
        "åœ¨æˆ‘çš„è³‡æ–™åº«ä¸­", "in my training data"
    ]
    
    def detect_information_source(self, response_text: str, provider: str) -> Dict:
        response_lower = response_text.lower()
        
        # Perplexity é è¨­ä½¿ç”¨ç¶²è·¯æœå°‹
        if provider == "Perplexity":
            return {
                "uses_online_search": True,
                "confidence": 0.95,
                "source_type": "Real-time Search",
                "indicators": ["Perplexity default behavior"]
            }
        
        # æª¢æ¸¬ç·šä¸Šæœå°‹æŒ‡ç¤ºå™¨
        online_matches = [ind for ind in self.ONLINE_INDICATORS 
                         if ind.lower() in response_lower]
        
        # æª¢æ¸¬çŸ¥è­˜æˆªæ­¢æŒ‡ç¤ºå™¨
        cutoff_matches = [ind for ind in self.KNOWLEDGE_CUTOFF_INDICATORS 
                         if ind.lower() in response_lower]
        
        if online_matches:
            return {
                "uses_online_search": True,
                "confidence": 0.8,
                "source_type": "Online Search",
                "indicators": online_matches
            }
        elif cutoff_matches:
            return {
                "uses_online_search": False,
                "confidence": 0.8,
                "source_type": "Training Data",
                "indicators": cutoff_matches
            }
        else:
            return {
                "uses_online_search": None,
                "confidence": 0.0,
                "source_type": "Unknown",
                "indicators": []
            }
```

#### UI é¡¯ç¤º

**è³‡è¨Šä¾†æºæŒ‡ç¤ºå™¨**ï¼š
```python
def render_information_source_indicators(self, ai_response):
    source_info = self.detect_information_source(
        ai_response.response_text, 
        ai_response.provider
    )
    
    if source_info["uses_online_search"] is True:
        st.success(f"ğŸŒ {ai_response.provider}: Online Search")
    elif source_info["uses_online_search"] is False:
        st.info(f"ğŸ“š {ai_response.provider}: Training Data")
    else:
        st.warning(f"â“ {ai_response.provider}: Source Unknown")
    
    # é¡¯ç¤ºæª¢æ¸¬åˆ°çš„æŒ‡ç¤ºå™¨
    if source_info["indicators"]:
        with st.expander("ğŸ“ Detection Details"):
            for indicator in source_info["indicators"]:
                st.caption(f"â€¢ {indicator}")
```

### 5. ğŸ“š ä½¿ç”¨èªªæ˜å’ŒæŠ€è¡“æ¶æ§‹é é¢

#### å¯¦ç¾æ–¹æ¡ˆ

**Tab ç³»çµ±æ”¹é€ **ï¼š
```python
def run(self):
    st.title("ğŸ”¥ FireGEO Brand Analysis")
    st.markdown("**AI-powered brand visibility analysis across multiple providers**")
    
    # å»ºç«‹ Tab ç³»çµ±
    tab1, tab2 = st.tabs(["ğŸ¯ Brand Analysis", "ğŸ“š User Guide"])
    
    with tab1:
        # ç¾æœ‰çš„ä¸»è¦åˆ†æåŠŸèƒ½
        self.render_main_analysis()
    
    with tab2:
        # æ–°çš„ä½¿ç”¨èªªæ˜é é¢
        self.render_user_guide()
```

**ä½¿ç”¨èªªæ˜å…§å®¹è¨­è¨ˆ**ï¼š

1. **å¿«é€Ÿé–‹å§‹æŒ‡å—**
   - æ­¥é©Ÿå¼çš„æ“ä½œèªªæ˜
   - API é‡‘é‘°è¨­å®šæ•™å­¸
   - æœ€ä½³å¯¦è¸å»ºè­°

2. **æŠ€è¡“æ¶æ§‹èªªæ˜**
   - ç³»çµ±æ¶æ§‹åœ–
   - å·¥ä½œæµç¨‹åœ–
   - AI æä¾›å•†ç‰¹æ€§æ¯”è¼ƒ

3. **åŠŸèƒ½ç‰¹è‰²ä»‹ç´¹**
   - å“ç‰Œæª¢æ¸¬é‚è¼¯
   - æ”¯æ´çš„æ¨¡å‹åˆ—è¡¨
   - çµæœè§£è®€æŒ‡å—

4. **å¸¸è¦‹å•é¡Œè§£ç­”**
   - API é‡‘é‘°ç²å–æ–¹å¼
   - æˆæœ¬ä¼°ç®—æ–¹æ³•
   - æ•…éšœæ’é™¤æŒ‡å—

## ğŸ“ æ–°å¢æ–‡ä»¶çµæ§‹

```
src/firegeo/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ token_tracking/              # æ–°å¢ï¼šToken è¿½è¹¤æ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ tracker.py               # Token ç”¨é‡çµ±è¨ˆ
â”‚   â”‚   â”œâ”€â”€ cost_calculator.py       # æˆæœ¬è¨ˆç®—
â”‚   â”‚   â””â”€â”€ pricing_config.py        # å®šåƒ¹é…ç½®
â”‚   â”œâ”€â”€ analytics/                   # æ–°å¢ï¼šåˆ†ææ¨¡çµ„  
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ visibility_calculator.py # å“ç‰Œå¯è¦‹åº¦è¨ˆç®—
â”‚   â”‚   â”œâ”€â”€ competitive_analyzer.py  # ç«¶çˆ­åŠ›åˆ†æ
â”‚   â”‚   â””â”€â”€ search_detector.py       # æœå°‹èƒ½åŠ›æª¢æ¸¬
â”‚   â””â”€â”€ enhanced_providers/          # æ–°å¢ï¼šå¢å¼·ç‰ˆæä¾›å•†
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ enhanced_openai.py       # æ”¯æ´æ¨¡å‹é¸æ“‡çš„ OpenAI
â”‚       â”œâ”€â”€ enhanced_anthropic.py    # æ”¯æ´æ¨¡å‹é¸æ“‡çš„ Anthropic
â”‚       â”œâ”€â”€ enhanced_google.py       # æ”¯æ´æ¨¡å‹é¸æ“‡çš„ Google
â”‚       â””â”€â”€ enhanced_perplexity.py   # æ”¯æ´æ¨¡å‹é¸æ“‡çš„ Perplexity
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ enhanced_analysis.py         # æ–°å¢ï¼šå¢å¼·åˆ†ææ¨¡å‹
â”‚   â””â”€â”€ dashboard_models.py          # æ–°å¢ï¼šå„€è¡¨æ¿è³‡æ–™æ¨¡å‹
â””â”€â”€ components/                      # æ–°å¢ï¼šUI çµ„ä»¶
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ model_selector.py            # æ¨¡å‹é¸æ“‡å™¨çµ„ä»¶
    â”œâ”€â”€ cost_tracker.py              # æˆæœ¬è¿½è¹¤é¡¯ç¤º
    â”œâ”€â”€ visibility_dashboard.py      # å¯è¦‹åº¦å„€è¡¨æ¿
    â””â”€â”€ user_guide.py                # ä½¿ç”¨èªªæ˜çµ„ä»¶
```

## ğŸš€ å¯¦ç¾å„ªå…ˆç´šå»ºè­°

### Phase 1 - åŸºç¤å¢å¼· (2-3å¤©)
1. **æ¨¡å‹é¸æ“‡åŠŸèƒ½**
   - ä¿®æ”¹ç¾æœ‰ AI Provider é¡åˆ¥
   - æ–°å¢æ¨¡å‹é…ç½®å’Œé¸æ“‡ UI
   - åœ¨çµæœä¸­é¡¯ç¤ºä½¿ç”¨çš„æ¨¡å‹

2. **åŸºç¤ Token çµ±è¨ˆ**
   - å¯¦ç¾ TokenTracker é¡åˆ¥
   - æ–°å¢åŸºç¤æˆæœ¬è¨ˆç®—
   - åœ¨ UI ä¸­é¡¯ç¤ºç”¨é‡çµ±è¨ˆ

3. **ä½¿ç”¨èªªæ˜é é¢**
   - æ–°å¢ Tab ç³»çµ±
   - å¯¦ç¾ä½¿ç”¨èªªæ˜å…§å®¹
   - æ·»åŠ æŠ€è¡“æ¶æ§‹èªªæ˜

### Phase 2 - åˆ†æå¢å¼· (3-4å¤©)
1. **å“ç‰Œå¯è¦‹åº¦å„€è¡¨æ¿**
   - å¯¦ç¾å¯è¦‹åº¦è¨ˆç®—é‚è¼¯
   - æ–°å¢äº’å‹•å¼ç†±åŠ›åœ–
   - å“ç‰Œåˆ‡æ›åŠŸèƒ½

2. **ç«¶çˆ­åŠ›è©•åˆ†ç®—æ³•**
   - é–‹ç™¼è©•åˆ†è¨ˆç®—é‚è¼¯
   - æ–°å¢æ¯”è¼ƒåˆ†æåŠŸèƒ½
   - çµ±è¨ˆè³‡æ–™å±•ç¤º

3. **æœå°‹èƒ½åŠ›æª¢æ¸¬**
   - å¯¦ç¾å…§å®¹åˆ†æé‚è¼¯
   - æ–°å¢ä¾†æºæŒ‡ç¤ºå™¨ UI
   - æª¢æ¸¬çµæœå±•ç¤º

### Phase 3 - UI/UX å„ªåŒ– (2-3å¤©)
1. **é«˜ç´šæˆæœ¬åˆ†æ**
   - è©³ç´°æˆæœ¬åˆ†è§£åœ–è¡¨
   - æˆæœ¬é ç®—æ§åˆ¶åŠŸèƒ½
   - æ­·å²ç”¨é‡è¿½è¹¤

2. **å¢å¼·åŒ¯å‡ºåŠŸèƒ½**
   - æ–°å¢è©³ç´°åˆ†æå ±å‘Š
   - å¤šç¨®æ ¼å¼æ”¯æ´
   - è‡ªå®šç¾©å ±å‘Šå…§å®¹

3. **æ•ˆèƒ½å„ªåŒ–**
   - ä¸¦è¡Œè™•ç†å„ªåŒ–
   - UI éŸ¿æ‡‰é€Ÿåº¦æå‡
   - éŒ¯èª¤è™•ç†æ”¹é€²

## ğŸ’° 2025å¹´æœ€æ–° AI æ¨¡å‹å®šåƒ¹æ¯”è¼ƒ

### æˆæœ¬æ•ˆç›Šåˆ†æè¡¨

| æä¾›å•† | æ¨¡å‹ | è¼¸å…¥æˆæœ¬ (per 1M tokens) | è¼¸å‡ºæˆæœ¬ (per 1M tokens) | ç‰¹æ®Šè²»ç”¨ | æ¨è–¦ç”¨é€” |
|--------|------|--------------------------|--------------------------|----------|----------|
| **OpenAI** | GPT-4o | $2.50 | $10.00 | - | é«˜å“è³ªåˆ†æ |
| **OpenAI** | GPT-4o-mini | $0.15 | $0.60 | - | å¤§é‡è«‹æ±‚ |
| **Anthropic** | Claude Sonnet 4 | $3.00 | $15.00 | - | å¹³è¡¡é¸æ“‡ |
| **Anthropic** | Claude Opus 4.1 | $15.00 | $75.00 | - | è¤‡é›œä»»å‹™ |
| **Google** | Gemini 2.5 Flash | $0.30 | $2.50 | - | å¤šæ¨¡æ…‹ |
| **Google** | Gemini 2.5 Flash Lite | $0.10 | $0.40 | - | **æœ€ç¶“æ¿Ÿ** |
| **Perplexity** | Sonar | $1.33 | $1.33 | $0.005/æœå°‹ | å³æ™‚æœå°‹ |
| **Perplexity** | Sonar Pro | $4.00 | $20.00 | $0.005/æœå°‹ | æ·±åº¦æœå°‹ |

### æˆæœ¬å»ºè­°ç­–ç•¥

#### ğŸ’¡ ç¶“æ¿Ÿå‹é…ç½®ï¼ˆé©åˆé ç®—æœ‰é™çš„ç”¨æˆ¶ï¼‰
- **ä¸»åŠ›æ¨¡å‹**: Gemini 2.5 Flash Lite ($0.10/$0.40)
- **æœå°‹éœ€æ±‚**: Perplexity Sonar ($1.33/$1.33 + æœå°‹è²»)
- **é ä¼°æˆæœ¬**: æ¯1000æ¬¡å“ç‰Œåˆ†æç´„ $0.5-2

#### ğŸ¯ å¹³è¡¡å‹é…ç½®ï¼ˆæ¨è–¦çµ¦å¤§å¤šæ•¸ç”¨æˆ¶ï¼‰
- **ä¸»åŠ›æ¨¡å‹**: GPT-4o Mini ($0.15/$0.60) + Gemini 2.5 Flash Lite
- **é«˜å“è³ªåˆ†æ**: Claude Sonnet 4 ($3/$15) ç”¨æ–¼é‡è¦æŸ¥è©¢
- **æœå°‹éœ€æ±‚**: Perplexity Sonar
- **é ä¼°æˆæœ¬**: æ¯1000æ¬¡å“ç‰Œåˆ†æç´„ $1-5

#### ğŸš€ å°ˆæ¥­å‹é…ç½®ï¼ˆé©åˆä¼æ¥­ç”¨æˆ¶ï¼‰
- **å…¨æ¨¡å‹è¦†è“‹**: GPT-4o, Claude Sonnet 4, Gemini 2.5 Flash, Perplexity Sonar Pro
- **æœ€é«˜å“è³ª**: æ‰€æœ‰ AI æä¾›å•†ä¸¦è¡Œåˆ†æ
- **é ä¼°æˆæœ¬**: æ¯1000æ¬¡å“ç‰Œåˆ†æç´„ $10-30

### ç‰¹æ®Šå®šåƒ¹æ©Ÿåˆ¶èªªæ˜

#### Perplexity æœå°‹è²»ç”¨è¨ˆç®—
```python
# Perplexity æˆæœ¬ = Token æˆæœ¬ + æœå°‹æˆæœ¬
total_cost = (input_tokens/1M * input_rate) + (output_tokens/1M * output_rate) + (searches * $0.005)

# ç¯„ä¾‹ï¼šä½¿ç”¨ Sonar Pro åˆ†æ 1 å€‹æç¤ºè©
# å‡è¨­ï¼šè¼¸å…¥ 1000 tokensï¼Œè¼¸å‡º 500 tokensï¼Œ1 æ¬¡æœå°‹
cost = (1000/1M * $4) + (500/1M * $20) + (1 * $0.005)
     = $0.004 + $0.01 + $0.005 = $0.019
```

#### Anthropic æ‰¹æ¬¡è™•ç†å„ªæƒ 
- **æ¨™æº– API**: æ­£å¸¸å®šåƒ¹
- **æ‰¹æ¬¡è™•ç†**: 50% æŠ˜æ‰£ï¼ˆé©åˆéå³æ™‚åˆ†æï¼‰
- **æç¤ºè©å¿«å–**: é«˜é” 90% ç¯€çœï¼ˆé‡è¤‡å…§å®¹ï¼‰

#### Google æ‰¹æ¬¡è™•ç†æŠ˜æ‰£
- **å³æ™‚æ¨¡å¼**: æ­£å¸¸å®šåƒ¹
- **æ‰¹æ¬¡æ¨¡å¼**: 50% æŠ˜æ‰£

## ğŸ¯ é æœŸæ•ˆç›Š

### å°ç”¨æˆ¶çš„åƒ¹å€¼
1. **é€æ˜åº¦æå‡**ï¼šæ¸…æ¥šäº†è§£ä½¿ç”¨äº†å“ªäº›æ¨¡å‹ã€èŠ±è²»å¤šå°‘æˆæœ¬
2. **æ§åˆ¶åŠ›å¢å¼·**ï¼šå¯ä»¥é¸æ“‡é©åˆçš„æ¨¡å‹å¹³è¡¡æˆæœ¬å’Œæ•ˆæœ
3. **æ´å¯ŸåŠ›æ·±åŒ–**ï¼šé€šéå„€è¡¨æ¿å¿«é€Ÿç™¼ç¾å“ç‰Œç«¶çˆ­åœ°ä½
4. **ä¿¡ä»»åº¦æå‡**ï¼šæ˜ç¢ºæ¨™ç¤ºè³‡è¨Šä¾†æºï¼ˆå…§å»ºçŸ¥è­˜ vs å³æ™‚æœå°‹ï¼‰
5. **æ˜“ç”¨æ€§æ”¹å–„**ï¼šè©³ç´°çš„ä½¿ç”¨æŒ‡å—é™ä½å­¸ç¿’æˆæœ¬

### æŠ€è¡“å„ªå‹¢
1. **æ¶æ§‹ç©©å®š**ï¼šä¿æŒç¾æœ‰æ¶æ§‹ç©©å®šæ€§ï¼Œå‘å¾Œç›¸å®¹
2. **æ¨¡çµ„åŒ–è¨­è¨ˆ**ï¼šæ–°åŠŸèƒ½ç¨ç«‹æ¨¡çµ„ï¼Œæ˜“æ–¼ç¶­è­·å’Œæ“´å±•
3. **æ“´å±•æ€§å¼·**ï¼šç‚ºæœªä¾†åŠŸèƒ½æ“´å±•å¥ å®šè‰¯å¥½åŸºç¤
4. **æ•ˆèƒ½å„ªåŒ–**ï¼šä¸¦è¡Œè™•ç†å’Œæ™ºèƒ½å¿«å–æå‡ç”¨æˆ¶é«”é©—

### å•†æ¥­åƒ¹å€¼
1. **å·®ç•°åŒ–ç«¶çˆ­**ï¼šç¨ç‰¹çš„å¤š AI æ•´åˆå’Œé€æ˜åº¦å„ªå‹¢
2. **ç”¨æˆ¶é»æ€§**ï¼šè±å¯Œçš„åˆ†æåŠŸèƒ½å’Œç›´è§€çš„ä½¿ç”¨é«”é©—
3. **å¸‚å ´æ“´å±•**ï¼šé©åˆä¸åŒè¦æ¨¡å’Œéœ€æ±‚çš„ä¼æ¥­ç”¨æˆ¶
4. **æˆæœ¬æ•ˆç›Š**ï¼šå¹«åŠ©ç”¨æˆ¶å„ªåŒ– AI API ä½¿ç”¨æˆæœ¬

## ğŸ’¡ å¾ŒçºŒç™¼å±•æ–¹å‘

1. **AI æ¨¡å‹æ“´å±•**ï¼šæ”¯æ´æ›´å¤š AI æä¾›å•†å’Œæ¨¡å‹
2. **æ­·å²æ•¸æ“šè¿½è¹¤**ï¼šå“ç‰Œå¯è¦‹åº¦è¶¨å‹¢åˆ†æ
3. **è‡ªå‹•åŒ–å ±å‘Š**ï¼šå®šæœŸå“ç‰Œç›£æ¸¬å’Œå ±å‘Šç”Ÿæˆ
4. **API æœå‹™åŒ–**ï¼šæä¾› REST API ä¾›ä¼æ¥­æ•´åˆ
5. **å¤šèªè¨€æ”¯æ´**ï¼šæ”¯æ´ä¸åŒèªè¨€çš„å“ç‰Œåˆ†æ

---

**ğŸ“… æ–‡æª”ç‰ˆæœ¬**ï¼šv1.0  
**ğŸ—“ï¸ å»ºç«‹æ—¥æœŸ**ï¼š2025-09-04  
**ğŸ‘¨â€ğŸ’» ä½œè€…**ï¼šClaude (Anthropic AI)  
**ğŸ”„ æœ€å¾Œæ›´æ–°**ï¼š2025-09-04